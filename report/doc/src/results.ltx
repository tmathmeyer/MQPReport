\section{Results}
\subsection{AST Compare vs Smith Waterman}
\subsubsection{Execution time}
The time taken by \textit{Checksims} to identify similarities is heavily
dependent upon the number of assignments being tested and by the algorithm used
to do the comparison. The following graphs show that the AST comparison
algorithm is significantly faster than Smith Waterman. While the amount of time
taken is rather trivial for smaller assignments, it is plausible to assume that
\textit{Checksims} may be run on a corpus with many hundreds of assignments; at
such a scale, the execution time may be many orders of magnitude different.
\input{runtime_plot_small.ltx}
\\
\\
This graph shows the number of seconds taken by both Smith Waterman and AST
Comparison to compute a similarity matrix for corpora with fewer than 100
assignments. A best fit line was constructed for each set of points, showing
that AST Fingerprinting ranges anywhere from 33 percent to 75 faster than the
Smith Waterman Algorithm. The raw data for this graph can be found in Appendix
E.
\\
\\
\input{runtime_plot_large.ltx}
\\
\\
This graph shows the number of seconds taken by both Smith Waterman and AST
Comparison to compute a similarity matrix for corpora with more than 100
assignments. A best fit line was constructed for each set of points, showing
that AST Fingerprinting ranges from 75 percent to 95 percent faster than
Smith Waterman. Raw data for this graph can be found in Appendix E.
\clearpage
\subsubsection{Identified Instances of Similarity}
\paragraph{In Python 3}
The five Python 3 corpora were each tested with both Smith Waterman and AST
Comparison. In corpus 4.a15.6 and 4.c15.6, neither Smith Waterman nor AST
Comparison identified any instances of similarity.

In corpus 4.a15.5, AST Comparison identified similarities between students 14
and 64, which were verified by hand; Smith Waterman did not detect any
similarity in this corpus.

In corpus 4.c15.5, AST Comparison identified similarities between
\begin{itemize}
    \item students 12 and 16
    \item students 18 and 34
    \item students 42 and 69
\end{itemize}
Smith Waterman identified similarities between
\begin{itemize}
    \item students 12 and 16
    \item students 10 and 53
\end{itemize}
Manual inspection of these four pairs of assignments show that it is highly
likely that the students in question were involved in unauthorized copying.

In corpus 4.c15.4, Smith Waterman
detected similarity between four pairs of students: 
\begin{itemize}
    \item students 54 and 8
    \item students 54 and 4
    \item students 71 and 20
    \item students 41 and 18
\end{itemize}
On this same corpus, AST Comparison detected similarities between the
following pairs of students:
\begin{itemize}
    \item students 54 and 8
    \item students 54 and 4
    \item students 41 and 18
    \item students 4 and 8
    \item students 84 and 42
    \item students 0 and 17
    \item students 83 and 79
\end{itemize}
Students 71 and 20 did not compile due to syntax errors created during the
anonymization process, as student names were included in parts of the code. AST
Analysis was therefore not able to have been run on this pair. It is
interesting that while Smith Waterman detected similarities between the pair
(54 and 8) and the pair (54 and 4), it did not detect similarity between the
pair (4 and 8), while AST Comparison did. Manual verification of these
assignments shows that all of them were likely instances of unauthorized
copying, though this was disputed for the pair of students 84 and 42.
\paragraph{In Java}
The single Java corpus was tested with both Smith Waterman and AST
Comparison. Smith Waterman detected similarities between the following:
\begin{itemize}
    \item students 229 and 21
    \item students 9 and 45
    \item students 195 and 80
\end{itemize}
AST Comparison detected similarities between:
\begin{itemize}
    \item students 229 and 21
    \item students 179 and 176
    \item students 196 and 219
    \item students 191 and 244
\end{itemize}
Manual inspection of these six pairs of assignments shows that student 9 did
not submit valid code, and could not be processed by AST Comparison, but was
most likely involved in a case of unauthorized copying with student 45.
Students 195 and 80 appeared to be very similar, but there were enough
differences to conclude that these two students did not engage in unauthorized
copying. All other four pairs were inspected and were found to have almost
certainly engaged in unauthorized copying.
\paragraph{In C89}
Of the seventy four available C89 corpora, twenty three assignments were
determined to be candidates for unauthorized copying detection. These twenty
three corpora were tested with both Smith Waterman and AST comparison.

In corpus 1.b12.2, AST comparison identified the following pair:
\begin{itemize}
    \item students 73 and 93
\end{itemize}
Smith Waterman identified the following pairs:
\begin{itemize}
    \item students 0 and 2
    \item students 85 and 91
\end{itemize}
Upon manual inspection, all were likely to be instances of unauthorized copying.


In corpus 1.b12.3, Smith Waterman identified the following pair:
\begin{itemize}
    \item students 87 and 89
\end{itemize}
Upon manual inspection, this pair was likely to be an instance of unauthorized
copying.

In corpus 1.b12.4, AST comparison identified the following pair:
\begin{itemize}
    \item students 79 and 82
\end{itemize}
Smith Waterman identified the following pairs:
\begin{itemize}
    \item students 79 and 82
    \item students 9 and 58
    \item students 58 and 72
\end{itemize}
Upon manual inspection, only the mutually identified pair was likely an instance
of unauthorized copying.

In corpus 1.b12.5, AST comparison identified the following pairs:
\begin{itemize}
    \item students 11 and 28
    \item students 11 and 84
    \item students 28 and 84
\end{itemize}
Smith Waterman identified the following pairs:
\begin{itemize}
    \item students 11 and 28
    \item students 11 and 84
    \item students 28 and 84
    \item students 8 and 29
    \item students 8 and 34
    \item students 29 and 34
    \item students 74 and 89
\end{itemize}
The first triplet was likely unauthorized copying. The second triplet contained
a syntax error, preventing the AST comparison method from parsing the
submission. The final identified pair was not significant.

In corpus 1.b12.6, AST comparison identified the following pairs:
\begin{itemize}
    \item students 8 and 39
    \item students 12 and 45
    \item students 24 and 62
    \item students 11 and 85
\end{itemize}
Smith Waterman identified the following pair:
\begin{itemize}
    \item students 74 and 89
\end{itemize}
The pairs identified by the AST comparison method were manually inspected and
likely to be instances of unauthorized. The pair identified by the Smith
Waterman method was not significant.

In corpus 1.b13.2, AST comparison identified the following pairs:
\begin{itemize}
    \item students 3 and 17
    \item students 57 and 76
\end{itemize}
Smith Waterman did not identify any submissions for review.
The pairs identified by the AST comparison method were manually inspected and
found to be very similar.

In corpus 1.b13.3, AST comparison identified the following pair:
\begin{itemize}
    \item students 1 4
\end{itemize}
Smith Waterman identified the following pair:
\begin{itemize}
    \item students 18 49
\end{itemize}
Both pairs were inspected and were likely instances of unauthorized copying.

In corpus 1.b13.4, AST comparison identified the following pair:
\begin{itemize}
    \item students 44 and 96
\end{itemize}
Smith Waterman identified the following pairs:
\begin{itemize}
    \item students 44 and 96
    \item students 65 and 85
\end{itemize}
Both pairs were inspected, and it was determined that they were probably instances
of unauthorized copying.

In corpus 1.b13.6, AST comparison identified the following pairs:
\begin{itemize}
    \item students 8 and 29
    \item students 32 and 45
\end{itemize}
Smith Waterman identified the following pairs:
\begin{itemize}
    \item students 16 and 70
    \item students 70 and 93
    \item students 16 and 93
    \item students 8 and 29
    \item students 32 and 45
    \item students 13 and 62
    \item students 6 and 48
    \item students 9 and 99
\end{itemize}
All discovered pairs were determined to be very similar.

In corpus 1.d11.2, AST comparison identified the following pairs:
\begin{itemize}
    \item students 12 and 48
    \item students 15 and 40
\end{itemize}
Smith Waterman identified the following pairs:
\begin{itemize}
    \item students 12 and 48
    \item students 15 and 40
    \item students 44 and 45
    \item students 9 and 26
    \item students 26 and 56
    \item students 9 and 56
    \item students 35 and 56
\end{itemize}
All discovered pairs were determined to be very similar, with the exception of
the final pair discovered by Smith Waterman.

In corpus 1.d11.3, AST comparison identified the following pairs:
\begin{itemize}
    \item students 18 and 22
    \item students 43 and 52
    \item students 4 and 30
\end{itemize}
Smith Waterman identified the following pairs:
\begin{itemize}
    \item students 18 and 22
    \item students 43 and 52
    \item students 4 and 30
    \item students 4 and 43
    \item students 23 and 43
    \item students 30 and 43
    \item students 44 and 49
    \item students 2 and 16
\end{itemize}
All pairs common to both methods were correctly identified as very similar,
along with the submissions of students 4 and 43 and students 2 and 16.

In corpus 1.d11.4, AST comparison identified the following pair:
\begin{itemize}
    \item students 25 and 41
\end{itemize}
Smith Waterman reported no similarities for this corpus.
The pair was inspected and found to be very similar.

In corpus 1.d12.2, both AST and Smith Waterman comparison identified the
following pairs:
\begin{itemize}
    \item students 28 and 29
    \item students 19 and 44
\end{itemize}
They were determined to be very similar.

In corpus 1.d12.3, AST comparison identified the following pairs:
\begin{itemize}
    \item students 5 and 26
    \item students 11 and 52
    \item students 20 and 55
\end{itemize}
Smith Waterman identified the following pairs:
\begin{itemize}
    \item students 11 and 52
    \item students 20 and 55
\end{itemize}
Upon manual inspection, the submissions from students 11 and 52 were determined
to be free of unauthorized copying. The others were found to be very similar.

In corpus 1.d12.4, AST comparison identified the following pairs:
\begin{itemize}
    \item students 26 and 36
    \item students 26 and 44
    \item students 36 and 44
\end{itemize}
Smith Waterman identified the following pairs:
\begin{itemize}
    \item students 26 and 36
    \item students 26 and 44
    \item students 36 and 44
    \item students 2 and 46
\end{itemize}
All pairs were determined to be potential instances of unauthorized copying.


In corpus 1.d12.6, AST comparison identified the following pairs:
\begin{itemize}
    \item students 26 and 27
    \item students 26 and 41
    \item students 27 and 41
    \item students 12 and 29
\end{itemize}
Smith Waterman identified the following pairs:
\begin{itemize}
    \item students 26 and 27
    \item students 26 and 41
    \item students 27 and 41
    \item students 3 and 12
    \item students 34 and 45
    \item students 12 and 43
\end{itemize}
All pairs were manually inspected, and all but submissions 13 and 43 were
found to be very similar.

Neither comparison method found similar submissions in the 1.d13.2 corpus.

In corpora 1.d13.3, 1.d13.4, and 1.d13.6, both Smith Waterman and AST comparison
identified a single similar pair. In 1.d13.3, the pair was:
\begin{itemize}
    \item students 45 and 62
\end{itemize}
In 1.d13.4, the following pair was found:
\begin{itemize}
    \item students 11 and 60
\end{itemize}
In 1.d13.6, the following pair was identified:
\begin{itemize}
    \item students 37 and 58
\end{itemize}
In corpora 1.d13.3 and 1.d13.4, the pairs were found to be very similar. In
corpus 1.d13.6, the pair was found to be sufficiently unique.

Over these twenty three corpora, there are cases where one algorithm
identifies submissions not identified by the other, instances where both
algorithms agree that two mostly unique assignments warrant investigation, and
unknown cases where neither method would report similar submissions. Of the
submissions positively identified by the Smith Waterman comparison method but
not by the AST comparison method, a number of causes have been discovered. The
two primary problems are submissions containing syntax errors, which cannot be
compared using the AST comparison method, and submissions with significantly
altered top level expressions, such as changing a method's prototype, or
converting between the different types of loop statements. Over the corpora,
a number of reverse cases are discovered, where AST comparison discovers
similar pairs that are missed by Smith Waterman.


\paragraph{In C++11}

\subsection{AST Comparison vs MOSS}
\subsubsection{Execution Time}
MOSS takes on average 14.5 seconds longer to run than the AST Comparison
algorithm on machine S1. Closer inspection of execution time shows that this is
almost entirely due to the process of uploading sometimes hundreds of files to
the Stanford University server where MOSS is run. Subtracting the execution
time of the upload step, the average execution time actually changes to 0.8
seconds in favor of MOSS\@.

\subsubsection{Identified Instances of Similarity}
For corpora 3.a13.1, 3.a13.2, 3.a13.3, 3.a12.1, 3.a12.2, and 3.a12.3, MOSS and
AST Compare reported the same set of pairs as being likely matches. When corpus
2.b14.2 was provided to the AST Compare algorithm, 4 pairs of assignments were
marked as being highly likely to contain instances of copying; that is, both
the matching value and inverse matching value between both assignments were
greater than 70 percent. MOSS only managed to catch a single pair of
assignments however. The significant pairs, in which either assignment matches
another greater than 69 percent are shown:
\\
\\
\begin{minipage}{\linewidth}
    \centering
    \captionof{table}{MOSS vs AST Compare, Corpus 2.b14.2}\label{mossvast} 
    \begin{tabular}{@{}lll@{}}
        \toprule
        Assignments          & AST Compare percentages & MOSS percentages  \\ \midrule
        students 229 and 21  & 81 and 83 percent       & 60 and 60 percent \\
        students 179 and 176 & 74 and 79 percent       & 17 and 17 percent \\
        students 196 and 219 & 73 and 71 percent       & 23 and 17 percent \\
        students 211 and 191 & 72 and 69 percent       & nothing reported  \\
                             &                &      \\ \bottomrule
    \end{tabular}
\end{minipage}
\\
\\
All four assignments have been manually reviewed as well, and it was determined
that these students would have been called in to discuss academic dishonesty
with the Professor. That MOSS missed these assignments provides significant
evidence to show that AST Comparison is at least as good, if not better, than
the closed source algorithm that powers MOSS\@.
