\section{Existing Literature}
Heon and Murvihill put together a large and comprehensive review of existing
literature on similarity detection in their original \textit{Checksims}
\cite{checksims1} paper. Many of the definitions and terms used herein are
based on their work.  The original codebase they created has also been extended
as part of this project.

\subsection{Academic Dishonesty}
The Heon and Murvihill provided a comprehensive set of examples and scenarios
where academic dishonesty is the hardest to distinguish. As they noted, an
instance of ``100\% similarity was almost certainly indicitive of unauthorized
copying''~\cite{checksims1}, but there are many scenarios where determining
whether a submission constitutes dishonest behavior is not as simple.

\subsection{Detecting Academic Dishonesty}
Code similarity detection is a practice that is used for identifying academic
dishonesty, duplicate code in large code bases for the purpose of optimisation
and cleaning, and for identifying instances of copyright infringement. While
these goals differ in minor ways, they generally share the same base goal: to
identify duplication despite intentional obfuscation or accidental duplication.
This section discusses the types of identification methods and particular
methods developed while reviewing existing literature.

\subsubsection{Detection of Dishonesty using Textual Comparison Techniques}
Heon and Murvihill thoroughly reviewed a number of existing methods of
identifying duplicate code. As \textit{Checksims} was originally intended to
perform language independent identification, it did not use syntax tree based
methods. Heon and Murvihill evaluated many methods for textual comparison and
settled on the Smith-Waterman algorithm as the best option.

\subsubsection{Detection of Dishonesty using Syntax Trees}
The original \textit{Checksims} paper also mentioned that  detecting academic
dishonesty in programming assignments is significantly easier than detecting
dishonesty in natural language. This is due to the fact that programming
languages follow highly specific grammars that are designed to be understood by
computer programs called compilers, and are significantly simpler than grammars
for natural written languages.  LISP programming languages such as Guile,
Scheme, and CommonLISP are all fairly popular in academic settings and in niche
industrial settings. LISP was developed by John McCarthy at the Massachusetts
Institute of Technology in 1958~\cite{original-lisp}. Despite its continued use
and popularity for over 50 years, the grammar for LISP is incredibly simple.
The following is an example grammar for the LISP language, expressed as an
ANTLR~\cite{antlr-lang} grammr. 

\lstinputlisting{S-expr.g4} % SExpression (LISP) grammar file

This grammar definition shows that LISP languages are just textual
representations of N-dimensional trees, with IDs as leaf nodes and sExprs as
branches. The difficulty of detecting dishonesty by transforming text into an
AST is that if the submitted text does not correctly implement the expected
grammar, a tree cannot be generated and comparison cannot happen. This is
surprisingly common in student submissions for a course --- real world examples
used for testing show that about 2 to 4 percent of code submissions are not
valid for the language in which they are written.

% Throw in methods here from various papers.
\paragraph{Using the Vector Space Model on Syntax Trees}
In the \textit{STVsm}~\cite{STVsm} paper, Li, Shen, Li, Zhang, and Li posed an
interesting syntax tree based approach to similarity detection. The process
begins by generating an AST from C code. This AST is then transformed into a
string in the form of \textit{s-expressions}. To compare any two documents in
this way, multiple string similarity techniques may be applied, including
\textit{Levenshtein Distance}, \textit{Greedy String Tiling}, and the
\textit{Vector Space Model Method}~\cite{STVsm}.  This idea is novel for a
number of reasons. It is based on the syntax tree of the associated language,
but it does not directly rely on comparing the structure of the syntax trees.
Instead, it generates a ``sanitized''  version of the document, and uses
generic text comparison methods to detect similarities. This allows the methods
to ignore plaintext obfuscation that would not appear on the AST, and had
improved results over plaintext comparison methods.

\paragraph{Syntax Tree Fingerprinting}
Syntax Tree Fingerprinting presents an efficient method of locating
structurally similar portions of two syntax trees~\cite{STFingerprinting}. The
fingerprinting technique stores each tree in two forms: an original AST
structure and as a mapping from ``fingerprint'' to a node of the tree. A
fingerprint is another name for a hash or checksum, and one example would be a
cryptographic hash of string tags on each node. This mapping needs only to be
generated once, as it is not modified during the comparison process. There are
many ways to generate a fingerprint for an AST, including cryptographic hashes
and rolling checksums. The Syntax Tree Fingerprinting method for comparison was
chosen for use
in \textit{Checksims}.
