\section{Existing Literature}
A large portion of the work done is based on the work put forth in the original
\textit{Checksims} paper\cite{checksims1}. This includes not only the code that
was produced in that project, but also the definitions and literature review
that was conducted. Many of the definitions and terms discussed from here on
can be directly attributed to their work.

\subsection{Academic Dishonesty}
The original \textit{Checksims} authors provided a comprehensive set of
examples and scenarios where academic dishonesty is the hardest to
distinguish. As they noted, an instance of ``100\% similarity was almost
certainly indicitive of unauthorized copying''\cite{checksims1}, but there are
many scenarios where determining whether a submission constitutes dishonest
behavior is not as simple.
% Throw in a few papers here, discuss various standards.

\subsection{Detecting Academic Dishonesty} There have been numerous approaches
to detecting duplicate code. Researchers primarily attempt to identify academic
dishonesty, duplicated code in codebases, and / or copyright infringement in
various samples of code. While different goals, these methods share the same
task: to identify duplication despite obfuscation tactics. This section
discusses the types of identification methods and particular methods developed
while reviewing existing literature.

\subsubsection{Detection of Dishonesty using Textual Comparison Techniques} The
original \textit{Checksims} paper thoroughly reviews a number of existing
methods of identifying duplicate code. As \textit{Checksims} was dedicated to
language independent identification, it did discussed, but did not heavily
focus on syntax tree based methods. The original \textit{Checksims} team
evaluated many methods for textual comparison and decided that the
Smith-Waterman algorithm would be the best option.

\subsubsection{Detection of Dishonesty using Syntax Trees}
The original \textit{Checksims} paper also mentioned that  detecting academic
dishonesty in programming assignments is significantly easier than detecting
dishonesty in natural language. This is due to the fact that programming
languages follow highly specific grammars that are designed to be understood by
a computer program, and are significantly simpler than a grammar for natural
written language. Consider the grammar for the LISP family of programming
languages; in the grammar definition syntax of ANTLR, a lisp program would be
defined as the following:

\lstinputlisting{S-expr.g4} % SExpression (lisp) grammar file

Written long hand, this grammar states that any block of text between a
semicolon (;) character and a newline (\textbackslash{} n) character is
considered a comment and can be skipped for the purpose of parsing. An ``ID''
consists of any arrangement of the characters a---z, A---Z, and 0--9, and than
an ``sExpr'' consists of at least 1 child, where each child is either an ID or
an sExpr.

This grammar definition shows that LISP languages are just textual
representations of an N-dimensional tree, with IDs as leaf nodes and sExprs as
branches. The difficulty of detecting dishonesty by transforming text into
an AST is that if the submitted text does not correctly implement the expected
grammar, a tree cannot be generated and comparison cannot happen. This is
surprisingly common in student submissions for a class --- real world examples
used for testing show that about 2 to 4 percent of code submissions are not
valid for the language in which they are written.

% Throw in methods here from various papers.
\paragraph{Using the Vector Space Model on Syntax Trees}
The STVsm paper posed an interesting syntax tree based approach to similarity
detection. In the STVsm paper, an AST is generated from C code. This AST is
then transformed back into a sring of s-expressions. To compare any two
documents, multiple string similarity techniques could be applied, including
\textit{Levenshtein Distance}, \textit{Greedy String Tiling}, and the
\textit{Vector Space Model} method\cite{STVsm}.  This idea is novel for a
number of reasons. It is based on the syntax tree of the associated language,
but it does not directly rely on comparing the structure of the syntax trees.
Instead, it generates a ``sanitized''  version of the document, and uses
generic text comparison methods to detect similarities. This allows the methods
to ignore plaintext obfuscation that would not appear on the AST, and had
improved results over plaintext comparison methods.

\paragraph{Syntax Tree Fingerprinting}
Syntax Tree Fingerprinting presents an efficient method of locating
structurally similar portions of two syntax trees\cite{STFingerprinting}. The
fingerprinting technique stores each tree in two forms: an original AST
structure, but also as a mapping from ``fingerprint'' to a node of the tree. A
fingerprint is another name for a hash or checksum, and one example would be a
cryptographic hash of String tags on each node. This mapping needs only to be
generated once, as it is not modified during the comparison process. There are
many ways to generate a fingerprint of an AST, including cryptographic hashes
and rolling checksums, as well as techniques in weighting the scores for each
node. This method for comparison was chosen for use in \textit{Checksims}.
