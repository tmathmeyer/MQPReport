\section{User Guide}
\textit{Checksims} is a tool for detecting source code similarities in an
arbitrary number of user-provided programming projects. Its primary purpose is
to flag potential cases of academic dishonesty in programming assignments.
\textit{Checksims} is not intended to detect academic dishonesty on its own,
but rather to act as a tool to identify suspicious assignments for review by
course staff.

The \textit{Checksims} user interface was designed to allow course staff to
use \textit{Checksims} without havving to memorize command line arguments.

\subsection{Installing Checksims}
\textit{Checksims} is distributed as an executable Java package (\texttt{.jar}
file). As a Java application, \textit{Checksims} is cross-platform and should
run on any system capable of running a Java Virtual Machine (JVM). The
provided Jar file is completely self-contained and requires no installation,
and should be named as follows:

\begin{figure}[H]
\centering
\texttt{checksims-\checksimsver-jar-with-dependencies.jar}
\end{figure}


Note that \checksimsver~represents the current version of \textit{Checksims}
at the time of this writing, and may be different for the version you receive.

Note that \textit{Checksims} requires a Java 8 virtual machine. The
latest version of the Oracle JVM is recommended, and can be found at the
following URL:

\begin{figure}[H]
\centering
\url{https://www.java.com/en/download/index.jsp}
\end{figure}

A 64-bit processor and JVM are strongly recommended.  Some \textit{Checksims}
detectors can consume a substantial amount of memory, potentially more than the
4GB maximum available to a 32-bit JVM\@. A 64-bit JVM can prevent a number of
memory-related program crashes.


\subsection{Running Checksims}

\subsubsection{Window and OSX}
Both Windows and OSX have the ability to run \textit{.jar} files when they are
double clicked on. It is recommended to put the \textit{Checksims} executable
in either the folder where assignments are kept, or on the desktop for easy
access.

\subsubsection{Linux / Advanced Usage}
While some graphical environments for the linux based operating system have the
ability to run \textit{.jar} files through a double click, the recommended way
of running \textit{Checksims} is through a shell. To run a \textit{.jar} file
from the command line, use the following command:

\begin{figure}[H]
    \centering
    \texttt{java -jar PATH/TO/CHECKSIMS\_JAR.jar}
\end{figure}

This command can be put inside of a shell script for more convenient use.

\newpage

\subsection{Intacting with the Interface}
When \textit{Checksims} runs, the user will be presented with a reletively small window
bearing the \textit{Checksims} logo, shown below:

\begin{figure}
\label{fig:ui_splash}
    \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{./img/initial_run.png}
    \caption{Note that Java user interfaces are not consistent across operating
    systems. Yours may look a bit different.}
\end{figure}

To test assignments for similarities, you must first select all included
submissions, common code, and submission archives. Once you have selected your
archives and comparison method, you can begin the comparison. To add a
submission directory, an archive directory, or a common code directory, click
the associated button. It will add a new box where you may select a
\textit{Turnin} zip file or directory for submissions or archives, or a
directory for your common code. You may have an arbitrary number of each
category. All listed submissions, archives, and common code directories will be
included in the comparison. You must also select a comparison method. The UI
includes a help mode, which can be activated by clicking on the `Enable Help'
button.

\subsubsection{Submissions}
\textit{Checksims} supports a number of submission and archive formats. The
primary format is an assignment directory. Every subdirectory is counted as an
independent submission, and every file in the subdirectories are recursively
concatenated together to form the submission. If you are using one of the AST
based comparison methods, only files with the appropriate source file extensions
will be considered. Submissions may also be in the form of a \textit{Turnin}
assignment archive. These are ZIP files with a particular directory structure.

\subsubsection{Archives}
Archives are the same as submissions, but they are not checked for similarity.
In other words, every submission will be compared to every other submission and
every archive submission, but the archive submissions will not be compared to
each other. This is useful when testing if any students may have copied sections
from a submission in a previous year. Archives take the same format as
submissions, but are treated differently by \textit{Checksims}.

\subsubsection{Common Code}
Many assignments have starter code, or code that is common between all of the
submissions. Removing common code is not necessary, but it can make the
distinction between similar and dissimilar submissions more stark. To use common
code removal, place all common code for an assignment into a single directory,
and select that directory for common code removal in the main menu.

\subsubsection{Comparison Methods}
\textit{Checksims} provides a number of methods for comparing assignments.
There are two primary categories: token based and AST based comparison methods.
Token based methods parse a submission into a sequence of tokens. Tokens may be
the individual characters, whitespace separated words, or lines of a file. AST
based methods parse each file into a an Abstract Syntax Tree before comparison.
Because of this , token based methods do not depend on any particular language,
while AST based methods must be used on their target languages. Token based
methods are not be as capable in detecting language based obfuscation methods.
AST methods are language specific, and will fail if given an invalid
assignment. They are, however, much more capable in detecting language based
obfuscation methods.

There are two token based methods available in \textit{Checksims}. The first is
\textit{linecompare}, which searches for identical lines in each file. This is
the least robust method, but is extremely efficient. The next token based method
is \textit{Smith-Waterman}, a sequence alignment algorithm typically used in
analyzing genome data. This method has a high memory requirement, but is more
robust than \textit{linecompare}.

\textit{Checksims} provides four AST based comparison algorithms. All methods
first parse the language dependent submission into a language independent syntax
tree. If the submission uses invalid syntax, it may not be parsed correctly, and
comparison will fail. The four methods are \textit{cparser}, \textit{cppparser},
\textit{javaparser}, and \textit{pythonparser}.

\subsection{Interpreting and Filtering Results}
Once \textit{Checksims} has finished comparing the submissions, you will see a
screen like the one below. This presents a similarity matrix and some controls.
The controls on the left allow you to set a threshold similarity, search for
students by name, and print the results in a number of formats.


\begin{figure}
  \label{fig:results}
  \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{./img/results.png}
  \caption{An example of the results screen. Shows the similarity matrix on the
    right and controls on the left.}
\end{figure}

The region on the right shows a grid of similarity ratings. All numbers are the
percent similarity score between two submissions. Each row and each column
represents a single submission, and each box represents the score similarity
score when comparing the row submission to the column submission. The main
diagonal of the matrix is blank, as each submission need not be compared to
itself. To inspect a pair in more detail, click on the box. You will see some
basic information about the pair of submission, including the submission
lengths, their similarity, and their cross similarity scores. If you do not see
any submissions, there were either no valid submissions, or there were no scores
above the threshold defined in the left panel.

The left panel provides three controls. The threshold hides any submissions that
have no similarity ratings above a certain number. This is useful when filtering
out dissimilar submissions. The second control provides two textboxes. Each
textbox takes a partial name and highlights any submissions under that name. For
instance, if you want to compare Alice and Bob, you can type their names into
the respective boxes. All students with the names Alice and Bob will be brought
to the front and highlighted, so you may review their similarity scores. The
third control allows you to export the results in a number of formats. You may
export an HTML document with the entire similarity matrix and simple formatting,
you may export the results as a CSV file, or you may export a text file
naming all pairs with a score greater than 70\%.
